<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Generating Multimodal Driving Scenes via Next-Scene Prediction">
  <meta name="keywords" content="DriveDreamer">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Generating Multimodal Driving Scenes via Next-Scene Prediction</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/ms_icon.png">

  <style>  
    table {  
      font-family: arial, sans-serif;  
      border-collapse: collapse;  
      width: 100%;  
    }  
      
    td, th {  
      border: 2px solid #F1F4F5;  
      text-align: left;  
      padding: 8px;  
    }  
    tr:nth-child(3n - 1) {  
      background-color: #F1F4F5;  
    }  

    tr:nth-child(3n) {  
      border: 2px solid #FFFFFF;
    }  
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>带导航栏的页面</title>
    <style>
        .sidebar {
            width: 250px;
            height: 100vh;
            background-color: #333; /* 深色背景 */
            color: white; /* 文字颜色 */
            padding: 20px;
            position: fixed;
        }
        .sidebar a {
            display: block;
            color: white;
            padding: 10px;
            text-decoration: none;
        }
        .sidebar a:hover {
            background-color: #575757;
        }
    </style>
</head>
<body>

<div class="sidebar">
    <h2></h2>
    <a href="#People_and_Teaser">Introduction</a>
    <a href="#Abstract">Abstract</a>
     <a href="#Method">Method</a>
    <a href="#Visualization">Visualization</a>
    <div class="submenu">
        <a href="#Autoregressive_Scene" style="margin-left: 15px;">- Demonstration of Autoregressive Scene Generation</a>
        <a href="#Generate_Scenes" style="margin-left: 15px;">- Multi-modal Driving Scene Generation</a>
        <a href="#Interactive_Ego_Control" style="margin-left: 15px;">- Interactive Ego-vehicle Control</a>
        <a href="#User_Scene" style="margin-left: 15px;">- User-Specified Scene Generation</a>
        <a href="#Diffusion_Scene" style="margin-left: 15px;">- Video Enhancement via a Diffusion Model</a>

    </div>
</div>

</body>
</html>



<section class="hero">
  <section id="People_and_Teaser">

  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Generating Multimodal Driving Scenes via Next-Scene Prediction</h1>
          <h2 class="is-size-2">CVPR 2025</h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yanhaowu.github.io/">Yanhao Wu</a><sup>1, 2</sup>,
            </span>
              <span class="author-block">
              <a href="https://scholar.google.com.hk/citations?user=PlMpgeIAAAAJ&hl=zh-CN&oi=ao">Haoyang Zhang</a><sup>2</sup>,
            </span>
              <span class="author-block">
              <a href="https://wzmsltw.github.io/">Tianwei Lin</a><sup>2</sup>,
            </span>
              <span class="author-block">
              <a href="https://www.linkedin.com/in/alanhuang1990/">Lichao Huang</a><sup>2</sup>,
            </span>
            <br>
            <span class="author-block">
              <a href="https://scholar.google.com.hk/citations?user=BDaj_esAAAAJ&hl=zh-CN&oi=ao/">Shujie Luo</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com.hk/citations?user=Z_ZkkbEAAAAJ&hl=zh-CN&oi=ao/">Rui Wu</a><sup>2</sup>,
            </span>
              <span class="author-block">
              <a href="https://congpeiqiu.github.io/">Congpei Qiu</a><sup>1</sup>,
            </span>
            <span class="author-block">
                <a href="https://gr.xjtu.edu.cn/en/web/wei.ke/home/">Wei Ke</a><sup>1</sup>,</span>
            </span>
            <span class="author-block">
              <a href="https://people.epfl.ch/tong.zhang?lang=en">Tong Zhang</a><sup>3, 4</sup>,
            </span>

          </div>


          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Xi'an Jiaotong University</span>&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>Horizon Roboics</span>&nbsp;&nbsp;
            <span class="author-block"><sup>3</sup>EPFL</span>&nbsp;&nbsp;
            <span class="author-block"><sup>4</sup>University of Chinese Academy of Sciences</span>&nbsp;&nbsp;
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2303.16235.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

<!--              <span class="link-block">-->
<!--                <a href="https://arxiv.org/pdf/2303.16235.pdf"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="ai ai-arxiv"></i>-->
<!--                  </span>-->
<!--                  <span>arXiv</span>-->
<!--                </a>-->
<!--              </span>-->

              <!-- Code Link. -->
<!--              <span class="link-block">-->
<!--                <a href="https://github.com/YanhaoWu/STSSL/"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-github"></i>-->
<!--                  </span>-->
<!--                  <span>Code</span>-->
<!--                  </a>-->
<!--              </span>-->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>










<!--<h3 class="title" style="margin-bottom: 15px; font-size: 22px; font-weight: bold; margin-left: 720px;">-->
<!--  A Unified <span style="font-weight: normal;">Multimodal</span> Driving Scene Generation Framework-->
<!--</h3>-->
<!--<h4 class="subtitle" style="margin-top: 7px; font-size: 18px; margin-left: 750px;">-->
<!--  <span style="font-weight: bold;">UMGen</span> generates complete self-driving scenes, including-->
<!--  <span style="font-weight: bold;">ego-vehicle actions</span>,-->
<!--  <span style="font-weight: bold;">maps</span>,-->
<!--  <span style="font-weight: bold;">traffic agents</span>, and-->
<!--  <span style="font-weight: bold;">images</span>—all purely synthesized by the model.-->
<!--</h4>-->




      <div class="container is-max-desktop">
        <div class="hero-body" style="padding-top: 0;">
          <div class="container is-max-desktop">
            <video preload="auto"poster="" id="tree" autoplay controls muted loop width="12000px" outline="0px">
              <source src=".\static\videos_example\0_Teaser_Video\Teaser_formated.mp4"
              type="video/mp4">
            </video>
              <figcaption style="font-size: 18px; margin-top: 10px; text-align: center; display: block;">
                  <span style="font-weight: bold;">UMGen</span> generates <span style="font-weight: bold;">multimodal</span> driving scenes, each scene
                  integrating <br>
                  1) <span style="font-weight: bold;">ego-vehicle actions</span>,
                  2) <span style="font-weight: bold;">raster maps</span>,
                  3) <span style="font-weight: bold;">traffic agents</span>, and
                  4) <span style="font-weight: bold;">images</span>.
                <br>
                  All visualized elements are generated by UMGen.
<!--                  <span style="font-weight: bold;">All visualized elements are generated by UMGen.</span>-->
              </figcaption>
        </div>
        </div>
      </div>
    </section>
  </div>
</section>





<!--  <section class="section">-->
<!--  <div class="container is-max-desktop">-->
<!--    &lt;!&ndash; Abstract. &ndash;&gt;-->
<!--&lt;!&ndash;    <div class="columns is-centered has-text-centered">&ndash;&gt;-->
<!--      <div class="column is-full_width">-->
<!--&lt;!&ndash;        <img src="static/Teaser.png" class="center"/>&ndash;&gt;-->
<!--        <h2 class="title is-3">What’s in This Project</h2>-->
<!--        <div class="content has-text-justified">-->
<!--          <p>-->
<!--          <style="line-height: 1.8;">-->
<!--           A Unified Multimodal driving scene Generation framework (UMGen) for self-driving scenes,-->
<!--           each containing four key modalities: ego-vehicle action, map, traffic agent, and image.</>-->
<!--        </div>-->
<!--&lt;!&ndash;      </div>&ndash;&gt;-->
<!--    </div>-->

<!--  </div>-->
<!--</section>-->


<section class="hero teaser">
  <div class="container is-max-desktop">
    <!-- <div class="hero-body"> -->
    <h2 class="title is-3">1. Overview</h2>
    <div class="item">
      <img src="static/Teaser.png" alt="MY ALT TEXT" />
      <h2 style="font-size: 18px" class="subtitle has-text-centered">
        <b>Overview of UMGen.
          <!-- <br> -->
        </b> (a) Starting from a random initialization, UMGen generates ego-centric, multimodal scenes frame-by-frame. Each scene encompasses four modalities: ego-vehicle action, map, traffic
agent, and image. (b) UMGen offers multiple functions. It can not only imagine multimodal scene sequences autonomously but can also predict
the other multimodalities based on input ego-vehicle actions. Furthermore, UMGen can incorporate user-specified agent actions to create
customized scene sequences.</h2>
    </div>
  </div>
</section>


  <section class="section">
      <section id="Abstract">

  <div class="container is-max-desktop">
    <!-- Abstract. -->
<!--    <div class="columns is-centered has-text-centered">-->
      <div class="column is-full_width">
<!--        <img src="static/Teaser.png" class="center"/>-->
        <h2 class="title is-3">2. Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Generative models in Autonomous Driving (AD) enable diverse scene creation,
            yet existing methods fall short by only capturing a limited range of modalities,
            restricting the capability of generating controllable scenes for comprehensive evaluation of AD systems.
            In this paper, we introduce a multimodal generation framework that incorporates four major data modalities, including a novel addition of map modality.
            With tokenized modalities, our scene sequence generation framework autoregressively predicts
            each scene while managing computational demands through a two-stage approach.
            The Temporal AutoRegressive (TAR) component captures inter-frame dynamics for each modality while the Ordered AutoRegressive (OAR) component
            aligns modalities within each scene by sequentially predicting tokens in a fixed order. To maintain coherence between map and ego-action modalities,
            we introduce the Action-aware Map Alignment (AMA) module, which applies a transformation based on the ego-action to maintain coherence between these modalities.
            Our framework effectively generates complex, realistic driving scenes over extended sequences,
            ensuring multimodal consistency and offering fine-grained control over scene elements.
        </div>
<!--      </div>-->
    </div>

  </div>
</section>

<style>
  .hero {
    margin-left: 20px; /* 添加左边距 */
  }
    .fade {
      opacity: 0.5;
      transition: opacity 0.5s;
    }
    .fade.active {
      opacity: 1;
    }
    .video-controls {
      text-align: center;
      margin-top: 10px;
    }
    .video-controls button {
      padding: 8px 16px;
      margin: 0 5px;
      font-size: 16px;
      cursor: pointer;
    }
</style>
<!-- Image carousel -->

<section class="hero teaser">
  <section id="Method">
  <div class="container is-max-desktop">
    <!-- <div class="hero-body"> -->
    <h2 class="title">3. Method</h2>
    <div class="item">
      <img src="static/method.png" alt="MY ALT TEXT" />
      <h2 style="font-size: 18px" >
        <b>Pipeline of our UMGen. </b>
        Given T past frames of multimodal driving scenes,
        including ego-action, maps, traffic agents, and images at each scene, each modality is tokenized into discrete tokens.
        The token embeddings are then processed through the Ego-action Prediction module, which forecasts the ego-action
        for T+1 time step. Using this predicted ego-action, the AMA module adjusts the map features.
        Next, the TAR module aggregates temporal information across sequences, while the OAR module ensures sequential
        prediction within each frame by autoregressively generating each token conditioned on the aggregated history information.
        Finally, the predicted tokens are fed to the decoder to obtain the next scene.</h2>
    </div>
  </div>
</section>
<!-- End image carousel -->

<style>
  #Method {
    margin-top: 60px; /* 根据需要调整间距大小 */
  }
</style>


<section class="section" id="Results"> <!-- 使用负 margin -->
   <section id="Visualization">

  <div class="container is-max-desktop">
      <div class="column is-full_width">
      <h2 class="title is-3">4. Visualization </h2>
<!--      <h3 class="title">Driving Scene Sequence Generation </h3>-->
<!--      (Four modalities in videos are generated by UMGen-->
    </section>
  </div>


          <div class="container is-max-desktop content">
        <section id="Autoregressive_Scene">

      <div style="font-size: 24px; margin-left: 45px; margin-top: -10px; margin-bottom: 30px;">
                              <br>
          A. <span style="font-weight: bold;">Demonstration of Autoregressive Scene Generation  </span>
      </div>
    <section class="hero method">
    <div class="container is-max-desktop">
        <div class="hero-body" style="padding-top: 0; display: flex; flex-direction: column; align-items: center; margin-bottom: -10px;">
            <video preload="auto" id="tree-long" autoplay controls muted loop
                style="width: 60%; max-width: 1600px;">
              <source src=".\static\videos_example\4_Example_AR\AR_example_formated.mp4" type="video/mp4">
            </video>
            <figcaption style="font-size: 18px; margin-top: 5px; text-align: center;">
              UMGen autoregressively generates four key modalities, <br>including <span style="font-weight: bold;"> ego-action, map, agent, and image, </span> within each frame.
            </figcaption>
        </div>
    </div>
    </section>



<div class="container is-max-desktop content">
      <div style="font-size: 24px; margin-left: 45px; margin-top: 20px; margin-bottom: 30px;">
          B. <span style="font-weight: bold;">Driving Scene Sequence Generation </span>
      </div>

<section class="hero method">
  <section id="Generate_Scenes">
    <div class="container is-max-desktop">
        <div class="hero-body" style="padding-top: 0; display: flex; flex-direction: column; align-items: center;">
            <video preload="auto" id="tree-long" autoplay controls muted loop
                style="width: 100%; max-width: 1600px;">
                <source src="./static/videos_example/1_Generated_Scenes/A_Generated_Long_Scenes/meraged_videos.mp4" type="video/mp4">
            </video>
            <figcaption style="font-size: 18px; margin-top: 5px; text-align: center;">
                <span style="font-weight: bold;">Long-duration</span> multi-modal driving scene generation.
                <span style="font-weight: bold;">All modalities</span> in the visualization are generated by UMGen.
            </figcaption>
        </div>
    </div>
</section>

  <section class="hero method">
    <div class="container is-max-desktop">
        <div class="hero-body" style="padding-top: 0; display: flex; flex-direction: column; align-items: center;">
            <video preload="auto" id="tree-long" autoplay controls muted loop
                style="width: 100%; max-width: 1600px; margin-bottom: 0px">
              <source src="./static/videos_example/1_Generated_Scenes/B_Generated_Diverse_Scenes/Diverse_video.mp4" type="video/mp4">
            </video>
            <figcaption style="font-size: 18px; margin-top: 5px; text-align: center;">
                <span style="font-weight: bold;">Diverse</span> multi-modal driving scene generation.
            </figcaption>
        </div>
    </div>
</section>



  

  <div class="container is-max-desktop content">
      <section id="Interactive_Ego_Control">
      <div style="font-size: 24px; margin-left: 45px; margin-top: -10px; margin-bottom: 30px;">
        <br>
          C. <span style="font-weight: bold;">Interactive Ego-vehicle Control </span>
      </div>

      <section class="hero method">
    <div class="container is-max-desktop">
        <div class="hero-body" style="padding-top: 0; display: flex; flex-direction: column; align-items: center;">
            <video preload="auto" id="tree-long" autoplay controls muted loop
                style="width: 70%; max-width: 1600px;">
              <source src=".\static\videos_example\2_Ego_Control\A_Intersection\combined_video.mp4" type="video/mp4">
            </video>
            <figcaption style="font-size: 18px; margin-top: 5px; text-align: center;">
                 The <span style="font-weight: bold;">ego-vehicle</span> is <span style="font-weight: bold;">controlled</span> to either drive straight or make a right turn at the intersection.
            </figcaption>
        </div>
    </div>
</section>

      <section class="hero method">

    <div class="container is-max-desktop">
        <div class="hero-body" style="padding-top: 0; display: flex; flex-direction: column; align-items: center; margin-bottom: -10px;">
            <video preload="auto" id="tree-long" autoplay controls muted loop
                style="width: 70%; max-width: 1600px;">
              <source src=".\static\videos_example\2_Ego_Control\B_Waiting\combined_video.mp4" type="video/mp4">
            </video>
            <figcaption style="font-size: 18px; margin-top: 5px; text-align: center;">
                 The <span style="font-weight: bold;">ego-vehicle</span> is <span style="font-weight: bold;">controlled</span> to either wait behind the agent or execute a lane change to overtake.
            </figcaption>
        </div>
    </div>
</section>



      <div class="container is-max-desktop content">
      <section id="User_Scene">

      <div style="font-size: 24px; margin-left: 45px; margin-top: -10px; margin-bottom: 30px;">
                <br>
          D. <span style="font-weight: bold;">User-Specified Scene Generation </span>
      </div>

    <section class="hero method">
    <div class="container is-max-desktop">
        <div class="hero-body" style="padding-top: 0; display: flex; flex-direction: column; align-items: center; margin-bottom: -10px;">
            <video preload="auto" id="tree-long" autoplay controls muted loop
                style="width: 90%; max-width: 1600px;">
              <source src=".\static\videos_example\3_User_Specified_Scenario_Generation\Userset_Scene.mp4"type="video/mp4">
            </video>
            <figcaption style="font-size: 18px; margin-top: 5px; text-align: center;">
           The <span style="font-weight: bold;">agent</span> is <span style="font-weight: bold;">controlled</span> to simulate a cut-in maneuver. The ego-vehicle is controlled to brake or to execute a lane change to avoid a collision.
            </figcaption>
        </div>
    </div>
    </section>



      <div class="container is-max-desktop content">
      <section id="Diffusion_Scene">

      <div style="font-size: 24px; margin-left: 45px; margin-top: -10px; margin-bottom: 30px;">
                              <br>
          E. <span style="font-weight: bold;">Video Enhancement via a Diffusion Model</span>
      </div>


<section class="hero method">
    <div class="container is-max-desktop">
        <div class="hero-body" style="padding-top: 0; display: flex; flex-direction: column; align-items: center;">

            <!-- 视频容器 -->
            <video id="videoPlayer" preload="auto" autoplay controls muted loop style="width: 100%; max-width: 1600px;">
                <source src="./static/videos_example/5_Diffusion/4.mp4" type="video/mp4">
                您的浏览器不支持 video 标签。
            </video>

            <!-- 切换按钮 -->
            <div style="margin-top: 10px; display: flex; gap: 10px;">
                <button onclick="changeVideo('./static/videos_example/5_Diffusion/4.mp4')">Scene 1</button>
                <button onclick="changeVideo('./static/videos_example/5_Diffusion/2.mp4')">Scene 2</button>
                <button onclick="changeVideo('./static/videos_example/5_Diffusion/3.mp4')">Scene 3</button>
                <button onclick="changeVideo('./static/videos_example/5_Diffusion/1.mp4')">Scene 4</button>
                <button onclick="changeVideo('./static/videos_example/5_Diffusion/5.mp4')">Scene 5</button>
<!--                <button onclick="changeVideo('./static/videos_example/5_Diffusion/6.mp4')">Scene 6</button>-->
            </div>

            <!-- 描述 -->
            <figcaption style="font-size: 18px; margin-top: 20px; text-align: center;">
                 We train a transformer-based diffusion model to further improve the quality of generated videos, leading to higher resolution, better visual clarity, and enhanced overall realism.
                <br>
                <span style="font-weight: bold;">Left</span>: Original UMGen-generated video, <span style="font-weight: bold;">Right</span>: Diffusion-refined UMGen-generated video.
            </figcaption>
        </div>
    </div>
</section>

<script>
    // JavaScript 函数：切换视频源
    function changeVideo(src) {
        const videoPlayer = document.getElementById('videoPlayer');
        videoPlayer.pause(); // 暂停当前视频
        videoPlayer.currentTime = 0; // 重置播放时间
        videoPlayer.src = src; // 设置新的视频源
        videoPlayer.play(); // 播放新视频
    }
</script>


<!--            <video preload="auto" id="tree-long" autoplay controls muted loop-->
<!--                style="width: 80%; max-width: 1600px;">-->
<!--              <source src=".\static\videos_example\5_Diffusion\0.mp4" type="video/mp4">-->
<!--            </video>-->


  </div></div></section>
  </div>
</section>
<!-- 感谢栏 -->
<footer style="text-align: center; padding: 20px; background-color: #f8f9fa; margin-top: 40px;">
<p>Thanks to <a href=https://github.com/GaoLianger" target="_blank">LiangGao</a>, <a href="https://mrcaesark.github.io/" target="_blank">Xiaohang Zeng</a>, and Wei Jin for their assistance in conducting experiments and developing visualizations.</p></footer>

</body>
</html>
